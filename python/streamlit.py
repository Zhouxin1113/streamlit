import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier  # åˆ†ç±»ä»»åŠ¡ç”¨åˆ†ç±»å™¨
from sklearn.metrics import (
    accuracy_score, confusion_matrix, 
    classification_report
)
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# 1. é¡µé¢é…ç½®ï¼ˆé€‚é…è‘¡è„é…’ä¸»é¢˜ï¼‰
st.set_page_config(page_title="è‘¡è„é…’åˆ†ç±»é¢„æµ‹å¹³å°", layout="wide")
st.title("ğŸ· è‘¡è„é…’åˆ†ç±»æœºå™¨å­¦ä¹ å¹³å°")
st.caption("åŸºäº wine.csv æ•°æ®ï¼Œé¢„æµ‹è‘¡è„é…’ç±»åˆ«ï¼ˆ1/2/3ç±»ï¼‰")

# 2. ä¼šè¯çŠ¶æ€åˆå§‹åŒ–ï¼ˆæŒä¹…åŒ–æ¨¡å‹/ç‰¹å¾/å‡å€¼ï¼‰
if 'trained_model' not in st.session_state:
    st.session_state.trained_model = None
if 'feature_cols' not in st.session_state:
    st.session_state.feature_cols = []
if 'feature_means' not in st.session_state:
    st.session_state.feature_means = {}

# 3. æ•°æ®ä¸Šä¼ ä¸åŠ è½½ï¼ˆæ”¯æŒä¸Šä¼ è‡ªå®šä¹‰wine.csvï¼Œä¹Ÿå¯é»˜è®¤åŠ è½½ç¤ºä¾‹ï¼‰
st.sidebar.header("1. æ•°æ®åŠ è½½")
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼  wine.csv æ–‡ä»¶", type="csv")

# å¤„ç†æ•°æ®åŠ è½½ï¼ˆä¼˜å…ˆç”¨ä¸Šä¼ æ–‡ä»¶ï¼Œæ— ä¸Šä¼ åˆ™ç”¨é»˜è®¤è·¯å¾„ï¼‰
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
else:
    # è‹¥ç”¨æˆ·æœªä¸Šä¼ ï¼Œå°è¯•åŠ è½½é»˜è®¤è·¯å¾„çš„wine.csvï¼ˆStreamlitéƒ¨ç½²æ—¶éœ€è°ƒæ•´è·¯å¾„ï¼‰
    try:
        df = pd.read_csv('/mnt/wine.csv')
        st.sidebar.success("å·²åŠ è½½é»˜è®¤ wine.csv æ•°æ®")
    except:
        st.sidebar.error("è¯·ä¸Šä¼  wine.csv æ–‡ä»¶æˆ–æ£€æŸ¥è·¯å¾„")

# 4. æ•°æ®é¢„å¤„ç†ä¸å±•ç¤ºï¼ˆä»…ä¿ç•™æ•°å€¼åˆ—ï¼Œå¤„ç†æ½œåœ¨ç¼ºå¤±å€¼ï¼‰
if 'df' in locals():
    # é¢„å¤„ç†ï¼šåˆ é™¤å…¨ç©ºåˆ—ï¼Œå¡«å……æ•°å€¼åˆ—ç¼ºå¤±å€¼ï¼ˆç”¨å‡å€¼ï¼‰
    df = df.dropna(axis=1, how='all')
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

    # å±•ç¤ºæ•°æ®æ ¸å¿ƒä¿¡æ¯
    st.subheader("ğŸ“Š æ•°æ®æ¦‚å†µ")
    col1, col2, col3 = st.columns(3)
    col1.metric("æ•°æ®è¡Œæ•°", df.shape[0])
    col2.metric("ç‰¹å¾åˆ—æ•°", len(numeric_cols)-1)  # æ’é™¤æ ‡ç­¾åˆ—
    col3.metric("è‘¡è„é…’ç±»åˆ«æ•°", df['class'].nunique() if 'class' in df.columns else 0)

    # æ•°æ®é¢„è§ˆï¼ˆå‰10è¡Œï¼‰
    st.dataframe(df.head(10), use_container_width=True)

    # 5. ç‰¹å¾ä¸æ ‡ç­¾é€‰æ‹©ï¼ˆé€‚é…wine.csvï¼Œé»˜è®¤æ ‡ç­¾åˆ—ä¸ºclassï¼‰
    st.sidebar.header("2. æ¨¡å‹è®¾ç½®")
    # ç‰¹å¾åˆ—ï¼šé»˜è®¤é€‰æ‹©é™¤classå¤–çš„æ‰€æœ‰æ•°å€¼åˆ—
    default_features = [col for col in numeric_cols if col != 'class']
    feature_cols = st.sidebar.multiselect(
        "é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰è‘¡è„é…’ç‰¹å¾ï¼‰",
        numeric_cols,
        default=default_features
    )
    # æ ‡ç­¾åˆ—ï¼šé»˜è®¤é€‰æ‹©classï¼ˆè‘¡è„é…’ç±»åˆ«ï¼‰
    label_col = st.sidebar.selectbox(
        "é€‰æ‹©æ ‡ç­¾åˆ—ï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰",
        numeric_cols,
        index=list(numeric_cols).index('class') if 'class' in numeric_cols else 0
    )

    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.feature_cols = feature_cols

    # 6. æ¨¡å‹è®­ç»ƒï¼ˆä»…å½“ç‰¹å¾å’Œæ ‡ç­¾éƒ½é€‰æ‹©åï¼‰
    if feature_cols and label_col and feature_cols != [label_col]:
        X = df[feature_cols]
        y = df[label_col]
        # è®¡ç®—ç‰¹å¾å‡å€¼ï¼ˆç”¨äºé¢„æµ‹é»˜è®¤å€¼ï¼‰
        st.session_state.feature_means = {col: float(X[col].mean()) for col in feature_cols}

        # åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆ8:2ï¼‰
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y  # åˆ†å±‚æŠ½æ ·ï¼Œä¿è¯ç±»åˆ«åˆ†å¸ƒ
        )

        # å±•ç¤ºæ•°æ®åˆ’åˆ†ç»“æœ
        st.write(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›† {X_train.shape} | æµ‹è¯•é›† {X_test.shape}")

        # è®­ç»ƒå‚æ•°è®¾ç½®ï¼ˆå†³ç­–æ ‘æ•°é‡ï¼‰
        n_estimators = st.sidebar.slider("å†³ç­–æ ‘æ•°é‡ï¼ˆéšæœºæ£®æ—ï¼‰", 10, 200, 100)

        # è®­ç»ƒæŒ‰é’®
        if st.sidebar.button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹"):
            with st.spinner("æ¨¡å‹è®­ç»ƒä¸­...ï¼ˆçº¦1-3ç§’ï¼‰"):
                # è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨
                model = RandomForestClassifier(
                    n_estimators=n_estimators,
                    random_state=42,
                    max_depth=10  # é™åˆ¶æ ‘æ·±ï¼Œé¿å…è¿‡æ‹Ÿåˆ
                )
                model.fit(X_train, y_train)
                # ä¿å­˜æ¨¡å‹åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.trained_model = model

                # æ¨¡å‹è¯„ä¼°
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)

                # å±•ç¤ºè¯„ä¼°ç»“æœ
                st.subheader("ğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ")
                st.metric("æµ‹è¯•é›†å‡†ç¡®ç‡", f"{accuracy:.4f}")  # æ ¸å¿ƒæŒ‡æ ‡

                # æ··æ·†çŸ©é˜µå¯è§†åŒ–
                fig, ax = plt.subplots(figsize=(6, 4))
                cm = confusion_matrix(y_test, y_pred)
                im = ax.matshow(cm, cmap=plt.cm.Greens)
                plt.colorbar(im, ax=ax)
                ax.set_xlabel("Predicted Class", fontsize=10)
                ax.set_ylabel("True Class", fontsize=10)
                ax.set_title("Confusion Matrixï¼ˆPredicted vs Trueï¼‰", fontsize=12)
                # æ ‡æ³¨æ•°å€¼
                for i in range(cm.shape[0]):
                    for j in range(cm.shape[1]):
                        ax.text(j, i, cm[i, j], ha='center', va='center', fontsize=12)
                st.pyplot(fig)

                # è¯¦ç»†åˆ†ç±»æŠ¥å‘Šï¼ˆç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ï¼‰
                st.subheader("ğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š")
                report = classification_report(
                    y_test, y_pred, output_dict=True
                )
                # è½¬æ¢ä¸ºDataFrameå±•ç¤º
                report_df = pd.DataFrame(report).T.round(4)
                st.dataframe(report_df, use_container_width=True)

    else:
        st.warning("è¯·é€‰æ‹©**ä¸åŒçš„ç‰¹å¾åˆ—å’Œæ ‡ç­¾åˆ—**ï¼ˆå»ºè®®æ ‡ç­¾åˆ—ä¸ºclassï¼‰")

# 7. åœ¨çº¿é¢„æµ‹æ¨¡å—ï¼ˆç‹¬ç«‹äºè®­ç»ƒæµç¨‹ï¼Œæ¨¡å‹è®­ç»ƒåæ°¸ä¹…å¯ç”¨ï¼‰
st.subheader("ğŸ” è‘¡è„é…’ç±»åˆ«åœ¨çº¿é¢„æµ‹")
if st.session_state.trained_model is None:
    st.info("è¯·å…ˆå®Œæˆã€Œæ•°æ®åŠ è½½â†’æ¨¡å‹è®­ç»ƒã€æ­¥éª¤åå†é¢„æµ‹")
else:
    # è¾“å…¥ç‰¹å¾å€¼ï¼ˆé»˜è®¤å¡«å……è®­ç»ƒé›†å‡å€¼ï¼‰
    st.caption("è¾“å…¥è‘¡è„é…’çš„ç‰¹å¾å€¼ï¼Œç‚¹å‡»é¢„æµ‹ç±»åˆ«ï¼ˆ1/2/3ï¼‰")
    input_data = {}
    for col in st.session_state.feature_cols:
        # ä»ä¼šè¯çŠ¶æ€è·å–å‡å€¼ä½œä¸ºé»˜è®¤å€¼
        default_val = st.session_state.feature_means.get(col, 0.0)
        # æ ¹æ®ç‰¹å¾å®é™…èŒƒå›´è°ƒæ•´è¾“å…¥æ¡†ï¼ˆä»¥ç»å…¸wineæ•°æ®ä¸ºä¾‹ï¼‰
        if col == 'alcohol':  # é…’ç²¾å«é‡é€šå¸¸8-15
            input_data[col] = st.number_input(f"{col}ï¼ˆé…’ç²¾å«é‡ï¼‰", value=default_val, min_value=8.0, max_value=15.0, step=0.1)
        elif col == 'malic_acid':  # è‹¹æœé…¸é€šå¸¸0.7-5.8
            input_data[col] = st.number_input(f"{col}ï¼ˆè‹¹æœé…¸ï¼‰", value=default_val, min_value=0.7, max_value=5.8, step=0.1)
        else:  # å…¶ä»–ç‰¹å¾ç”¨é»˜è®¤èŒƒå›´
            input_data[col] = st.number_input(f"{col}", value=default_val, min_value=0.0, step=0.01)

    # é¢„æµ‹æŒ‰é’®
    if st.button("âœ¨ å¼€å§‹é¢„æµ‹"):
        try:
            # è½¬æ¢è¾“å…¥ä¸ºDataFrameï¼ˆåŒ¹é…æ¨¡å‹è¾“å…¥æ ¼å¼ï¼‰
            input_df = pd.DataFrame([input_data])
            # é¢„æµ‹
            pred_class = st.session_state.trained_model.predict(input_df)[0]
            # å±•ç¤ºç»“æœ
            st.success(f"ğŸ‰ é¢„æµ‹ç»“æœï¼šè¯¥è‘¡è„é…’å±äº **{int(pred_class)}ç±»**")
            
            # å±•ç¤ºé¢„æµ‹æ¦‚ç‡ï¼ˆå¢åŠ å¯ä¿¡åº¦ï¼‰
            pred_proba = st.session_state.trained_model.predict_proba(input_df)[0]
            proba_df = pd.DataFrame({
                "è‘¡è„é…’ç±»åˆ«": [1, 2, 3],
                "é¢„æµ‹æ¦‚ç‡": [f"{p:.4f}" for p in pred_proba]
            })
            st.dataframe(proba_df, use_container_width=True)
        except Exception as e:
            st.error(f"é¢„æµ‹å‡ºé”™ï¼š{str(e)}")
